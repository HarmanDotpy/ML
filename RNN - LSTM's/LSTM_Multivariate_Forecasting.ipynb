{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanilla-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4ifcc4hFYOcLkoYws8R4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarmanDotpy/RNNs-LSTMs/blob/master/LSTM_Multivariate_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgF3iu8W35Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMmodel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMmodel, self).__init__() \n",
        "    \n",
        "    self.input_size = 3 #is the number of expected input features x\n",
        "    self.hidden_size = 50 # is the hidden layer size, ie its the size of a, the hidden state\n",
        "    self.num_layers = 2 # num layers is the number of stacked LSTM layersb we want\n",
        "    self.output_size = 3\n",
        "    self.seq_length = 3 \n",
        "    self.batch_size = 6\n",
        "    \n",
        "    self.lstm = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers, batch_first = True)\n",
        "    self.linear = nn.Sequential(\n",
        "                      nn.Linear(self.hidden_size, self.output_size),\n",
        "                      nn.ReLU()\n",
        "                  )\n",
        "  def init_hidden(self):\n",
        "    return (torch.randn(self.num_layers, self.batch_size, self.hidden_size) * 0.01,\n",
        "            torch.randn(self.num_layers, self.batch_size, self.hidden_size) * 0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    lstm_out, self.hidden = self.lstm(x)\n",
        "    # lstm_out has dimensions (batch, seq_length,num_directions * hidden_size)\n",
        "    y_pred = self.linear(lstm_out[:, -1, :].reshape(-1, self.hidden_size))\n",
        "    # y_pred has size batch_size * ouput_size\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fam4TSTVWs_l",
        "colab_type": "code",
        "outputId": "bc86cd7d-b7a0-4f09-890e-dd34242c546d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# This block of code is taken from https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "# Generating data in this block of code\n",
        "# multivariate output data prep\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(X.shape, y.shape)\n",
        "print(dataset.shape)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "\tprint(X[i], y[i])\n",
        "\n",
        "\n",
        "X_train = torch.Tensor(X)\n",
        "y_train = torch.Tensor(y)\n",
        "print(X_train.shape, y_train.shape)\n",
        "# X_train = X_train.reshape(X_train.shape[1], X_train.shape[0], X_train.shape[2])\n",
        "# print(X_train)\n",
        "# print(y_train)\n",
        "# print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 3, 3) (6, 3)\n",
            "(9, 3)\n",
            "[[10 15 25]\n",
            " [20 25 45]\n",
            " [30 35 65]] [40 45 85]\n",
            "[[20 25 45]\n",
            " [30 35 65]\n",
            " [40 45 85]] [ 50  55 105]\n",
            "[[ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]] [ 60  65 125]\n",
            "[[ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]] [ 70  75 145]\n",
            "[[ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]] [ 80  85 165]\n",
            "[[ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]] [ 90  95 185]\n",
            "torch.Size([6, 3, 3]) torch.Size([6, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0d_QoNdbJaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "fc63e6c9-eb99-4cb7-a325-8385768b4326"
      },
      "source": [
        "# initialize model\n",
        "model = LSTMmodel()\n",
        "\n",
        "\n",
        "# keeping batch size as total number of training examples\n",
        "learning_rate = 0.01\n",
        "batch_size = X.shape[0]\n",
        "lossfunction = nn.MSELoss(reduction = 'mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "num_epochs = 2000\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "# Training model\n",
        "for i in range(num_epochs):\n",
        "\n",
        "  # initialize hidden state\n",
        "  model.hidden = model.init_hidden()\n",
        "\n",
        "  # predict output\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  # calculate loss\n",
        "  loss = lossfunction(y_pred, y_train)\n",
        "  \n",
        "  # backpropogate\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if(i %100 ==0):\n",
        "    print('Epoch = {}, Loss = {}'.format(i, loss))\n",
        "  loss_list.append(loss)\n",
        "\n",
        "\n",
        "# NOTE : If model doesnot converge then try and re run it\n",
        "# my speculation is that some of the outputs always become zero due to \n",
        "# wrong initialization, hence re-running most of the time works"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 0, Loss = 9691.0869140625\n",
            "Epoch = 100, Loss = 3471.34619140625\n",
            "Epoch = 200, Loss = 1446.9765625\n",
            "Epoch = 300, Loss = 810.109130859375\n",
            "Epoch = 400, Loss = 629.9395751953125\n",
            "Epoch = 500, Loss = 278.9823303222656\n",
            "Epoch = 600, Loss = 123.60848236083984\n",
            "Epoch = 700, Loss = 68.57200622558594\n",
            "Epoch = 800, Loss = 31.07886505126953\n",
            "Epoch = 900, Loss = 21.40212059020996\n",
            "Epoch = 1000, Loss = 18.2934513092041\n",
            "Epoch = 1100, Loss = 17.28177833557129\n",
            "Epoch = 1200, Loss = 13.15811538696289\n",
            "Epoch = 1300, Loss = 4.206226348876953\n",
            "Epoch = 1400, Loss = 1.7791372537612915\n",
            "Epoch = 1500, Loss = 0.7641615867614746\n",
            "Epoch = 1600, Loss = 0.557267427444458\n",
            "Epoch = 1700, Loss = 0.15440508723258972\n",
            "Epoch = 1800, Loss = 0.08307984471321106\n",
            "Epoch = 1900, Loss = 0.04306900501251221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpY2_dM66it5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c6531fd2-ff3c-4381-fb10-52f32003b2df"
      },
      "source": [
        "# Testing if it generates the next output in the sequence\n",
        "model.eval()\n",
        "input = torch.Tensor([[[60, 65, 125], [70, 75, 145], [80, 85, 165]]])\n",
        "print(input.shape)\n",
        "out = model(input)\n",
        "print(out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 3])\n",
            "tensor([[ 90.1768,  95.0798, 184.2750]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh2zeAPPGS4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "fa755924-c977-44d4-ca7c-c5fdb2c19943"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_list)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}